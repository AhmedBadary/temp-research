---
layout: NotesPage
title: 5.5 <br /> Error Control and the Runge-Kutta-Fehlberg Method
permalink: /work_files/school/128a/5_5
prevLink: /work_files/school/5
---

<div markdown="1" class = "TOC">
# Table of Contents

  * [Adaptive Methods](#content1)
  {: .TOC1}
  * [Runge-Kutta-Fehlberg Method](#content2)
  {: .TOC2}
  * [THIRD](#content3)
  {: .TOC3}
  * [FOURTH](#content4)
  {: .TOC4}
</div>

***
***

## Adaptive Methods
{: #content1}

1. **What?**{: style="color: SteelBlue  "}{: .bodyContents1 #bodyContents11}  
    :   > Techniques used to control the error of a difference equation method in an efficient manner by the appropriate choice of mesh points.  
    :   > By using methods of differing order we can predict the local truncation error
    and, using this prediction, choose a step size that will keep it and the global error in check.

2. **Why?**{: style="color: SteelBlue  "}{: .bodyContents1 #bodyContents12}  
    :   **Adaptive Methods** incorporate in the step-size procedure an estimate of
    the truncation error that does not require the approximation of the higher derivatives of the function.  
    :   They **adapt** the number and position of the nodes used in the approximation to ensure that the truncation error is kept within a specified bound.

3. **Derivation:**{: style="color: SteelBlue  "}{: .bodyContents1 #bodyContents13} \\
    <button>Show Derivation</button>{: .showText value="show"
     onclick="showTextPopHide(event);"}
    ![formula](/main_files/128a/5/5.5/derivation.png){: width="80%" hidden=""}  
    
***

## Runge-Kutta-Fehlberg Method
{: #content2}

1. **What?**{: style="color: SteelBlue  "}{: .bodyContents2 #bodyContents21} \\
    ![formula](/main_files/128a/5/5.5/1.png){: width="60%"}

2. **Why?**{: style="color: SteelBlue  "}{: .bodyContents2 #bodyContents22} \\
    > An advantage to this method is that only six evaluations of f are required per step.  

    > As opposed to requiring at least four evaluations of $$f$$ for the fourth-order method and an additional six for the fifth-order method, for a total of at least ten function evaluations.  

    > $$\implies$$ This Method has at least a $$40\%$$ decrease in the number of function evaluations over the use of a pair of arbitrary fourth- and fifth-order methods.

3. **Error Bound Order:**{: style="color: SteelBlue  "}{: .bodyContents2 #bodyContents23} \\
    $$\mathcal{O}(h^5)$$

4. **The choice of "q":**{: style="color: SteelBlue  "}{: .bodyContents2 #bodyContents24} \\
    * The value of q determined at the ith step is used for two purposes:
        1. **When $$q < 1$$:** to reject the initial choice of $$h$$ at the ith step and repeat the calculations using $$qh$$, and
        2. **When $$q \geq 1$$: to accept the computed value at the ith step using the step size $$h$$, but change the step size to $$qh$$ for the (i + 1)st step.

    > Because of the penalty in terms of function evaluations that must be paid if the steps are repeated, q tends to be chosen conservatively.

    * The choice of q for the "Runge-Kutta-Fehlberg":
        ![formula](/main_files/128a/5/5.5/2.png){: width="60%"}

5. **Algorithm:**{: style="color: SteelBlue  "}{: .bodyContents2 #bodyContents25} \\
    <button>Show Derivation</button>{: .showText value="show"
     onclick="showTextPopHide(event);"}
    ![formula](/main_files/128a/5/5.5/alg.png){: width="80%" hidden=""}
    * Notice:
        1. Step 9 is added to eliminate large modifications in step size.
        2. This is done to avoid spending too much time with small step sizes in regions with irregularities in the derivatives of y, and to avoid large step sizes, which can result in skipping sensitive regions between the steps.
        3. The step-size increase procedure could be omitted completely from the algorithm.
        4. The step-size decrease procedure used only when needed to bring the error under control.
